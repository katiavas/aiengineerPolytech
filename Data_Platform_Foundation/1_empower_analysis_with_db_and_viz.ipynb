{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7109b95e-6adf-438c-93de-7ce9b56e20db",
   "metadata": {},
   "source": [
    "# Use databases and dataviz tools to empower analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137434e-e31f-4f3b-9178-2c5e0ccb701a",
   "metadata": {},
   "source": [
    "In this notebook we will get data from MinIO bucket, insert it into a database table and visualize outputs on an interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e27a0-c9ee-40ab-88ce-3319ca05f746",
   "metadata": {},
   "source": [
    "### 1.1.0 Get data from MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1552a-cc09-4dad-9fa9-7ec27194c17a",
   "metadata": {},
   "source": [
    "With the last notebook, create a minio client, get your parquet file and read it with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbadda-9402-4cc2-a4d6-b938a6527b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f12da9-9ebb-4b6d-959b-594429ba5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependancies\n",
    "from minio import Minio\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO, StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca45073-15fa-4522-bc60-9b6bd7e7033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a client with the access key and the secret key given\n",
    "import os\n",
    "client = Minio(\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0442ae8-ddb1-4627-a661-a476e1bd6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### path to the object into minIO\n",
    "path_minio=...\n",
    "\n",
    "### Reuse your bucket name\n",
    "bucket=''#name-surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8550550-87a2-4868-a503-18ef19fff38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from minio using get_object, decode it using BytesIO and read the parquet result with pandas\n",
    "try:\n",
    "    response = client....\n",
    "    # Read data from response.\n",
    "    parquet_object=...\n",
    "    data = pd....\n",
    "finally:\n",
    "    response.close()\n",
    "    response.release_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451202a-a845-412c-a42b-0b5bbe91934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data\n",
    "data...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdf0e8-3083-4a81-94da-08df6fc78b05",
   "metadata": {},
   "source": [
    "### 1.1.1 Clickhouse create db and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bcf31",
   "metadata": {},
   "source": [
    "Here we want to store our numerical features for futur analysis / model training / preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b9d91-f25d-4427-a091-ee9c5c642466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependancies : pandahouse, pandas client to talk with clickhouse \n",
    "%pip install pandahouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d547f-d9fa-4da8-9f4e-d89239ca345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import depandancies\n",
    "import pandahouse as ph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558eeb5-b1c8-4755-8497-97b78dce01cc",
   "metadata": {},
   "source": [
    "#### Create clickhouse connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382957eb-ad02-42ae-8578-5407a910d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The connection dict need a default database\n",
    "connection = dict(database='default',\n",
    "                  host='http://clickhouse-install.clickhouse.svc.cluster.local:8123',\n",
    "                  user='admin',\n",
    "                  password='B1gdata-demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f7c58-f3f2-49c7-9cda-8c0d858549e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute a show databases command to verify the connection is working\n",
    "ph.read_clickhouse('...',connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65811a-cd29-435d-a6f5-0d285cce7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper function for handle this python client\n",
    "def write_clickhouse(query,connection):\n",
    "    print(query)\n",
    "    try:\n",
    "        ph.read_clickhouse(query,connection=connection)\n",
    "    except KeyError:\n",
    "        print(\"Nothing to return\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed942c0c-62ec-46d5-9700-dfa3c9db2e55",
   "metadata": {},
   "source": [
    "**Create a db named firstname-lastname, as in your credentials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b938cfc-e050-42c2-8d84-3636468f4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstname_lastname, as in your credentials but with \"_\" instead of \"-\" because clickhouse does not allow \"-\" in db name\n",
    "dbname = ''#name_surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e796728-4283-459d-bbe7-f6d7151376cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a personal database if it does not exists\n",
    "write_clickhouse(f\" ... \",connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eef226-6f96-4316-a0bd-0669adeb7c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### override connection dict with personal database\n",
    "connection['database'] = f\"{dbname}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f03929-bae3-4c58-9fc4-2d62466976e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the connection content is related to your user\n",
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c465f4-261f-42b7-ab4e-c7385e3881f1",
   "metadata": {},
   "source": [
    "#### Create clickhouse table taxi_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36b0e6-a7aa-42d9-8399-eaf502316901",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtable='chicago_taxi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select features\n",
    "features = data[[\n",
    "    \"tips\",\n",
    "    \"trip_start_timestamp\",\n",
    "    \"trip_seconds\",\n",
    "    \"trip_miles\",\n",
    "    \"pickup_community_area\" ,\n",
    "    \"dropoff_community_area\" ,\n",
    "    \"fare\",\n",
    "    \"tolls\",\n",
    "    \"extras\",\n",
    "    \"trip_total\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa315da9-2402-4344-8db6-dbea9bf7e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create table for inserting taxi trip dataset \n",
    "## Clickhouse table definition\n",
    "# using the df informations, and clickhouse documentation write  the create table statement\n",
    "taxitable = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {dbname}.{dbtable}\n",
    "(\n",
    "    ...\n",
    ") \n",
    "ENGINE = MergeTree\n",
    "PARTITION BY toYYYYMM(trip_start_timestamp)\n",
    "ORDER BY trip_start_timestamp;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba0ce0-e7fe-47ed-b47c-45546d508f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_clickhouse(...,connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbfdc9-0b6d-4a63-b054-134c24da69fb",
   "metadata": {},
   "source": [
    "#### Insert the data into taxi_trips table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832901ae-6889-4078-86c0-7fda7267965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have to be compliant with the clickhouse date type. \n",
    "## we need to force '%Y-%m-%d %H:%M:%S'\n",
    "## force the date format with the defined schema, using pandas\n",
    "features[\"trip_start_timestamp\"] = pd...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9a1e9-3cf5-4c98-9869-951a8ea00fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert using the to_clickhouse function\n",
    "ph.to_clickhouse(features, dbtable, index=False, chunksize=100000, connection=connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012824ca",
   "metadata": {},
   "source": [
    "### 1.1.2 Postgresql Create db and table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12367a",
   "metadata": {},
   "source": [
    "Here we want to store a referential of pickup community area and related long / lat. To feed future map analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d18457-feb3-4133-8170-1020a98e86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef05f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import depandancies : psycopg2-binary\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the data we create a de-deduplicated, non null value referential\n",
    "scope = data[[\n",
    "    \"pickup_community_area\",\n",
    "    \"pickup_centroid_latitude\",\n",
    "    \"pickup_centroid_longitude\"\n",
    "    ]].drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the length of the referential is coherent\n",
    "len(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head some lines of the scoped data\n",
    "scope...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16fe16",
   "metadata": {},
   "source": [
    "#### Create postgres connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postgres is the default database, autocommit enable folder level actions\n",
    "conn = psycopg2.connect(\n",
    "   database=\"postgres\", user='postgres', password='B1gdata-demo', host='mypostgres.kubegres.svc.cluster.local', port= '5432'\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d546be",
   "metadata": {},
   "source": [
    "#### Create postgres personal DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbaaae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the postgres database name\n",
    "# firstname_lastname, as in your credentials but with \"_\" instead of \"-\" because postgres does not allow \"-\" in db name\n",
    "dbname = ''#name_surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the query to create a new database named with the dbname var\n",
    "sqlCreateDb = f\"\"\" create database {dbname}\"\"\"\n",
    "# execute the query using the cursor\n",
    "cursor.execute(sqlCreateDb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4235e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now overwrite the conn with your personnal DB\n",
    "conn = psycopg2.connect(\n",
    "   database=dbname, user='postgres', password='B1gdata-demo', host='mypostgres.kubegres.svc.cluster.local', port= '5432'\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3627934",
   "metadata": {},
   "source": [
    "#### Create table in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set table name\n",
    "table_name='chicago_areas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the right way to define the table using postgresql documentation\n",
    "# focus on schema and types\n",
    "# using the df informations, and postgres documentation write the create table statement\n",
    "\n",
    "areas_table=f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "   ...)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "## execute the table creation query\n",
    "cursor.execute(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064bddcf",
   "metadata": {},
   "source": [
    "#### Insert data into table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fffa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_df_to_table(df,table,conn,cursor):\n",
    "    \"\"\"\n",
    "    insert data to postgres table from pandas dataframe\n",
    "    \"\"\"\n",
    "    # prepare object to stream data\n",
    "    output = StringIO()\n",
    "    # put data into StringIO object as a csv \n",
    "    df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "    # replace output cursor position  position 0\n",
    "    output.seek(0)\n",
    "    # copy content from stream object to table\n",
    "    cursor.copy_from(output, table, null=\"\") # null values become ''\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "insert_df_to_table(...,...,...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c213ed3",
   "metadata": {},
   "source": [
    "#### Verify if content is loaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a select statement to get 5 top records of your areas table\n",
    "selectexp = f\" ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a88f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the base and return a Pandas dataframe using read_sql_query function from pandas\n",
    "frame = pd.read_sql_query(...,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663db82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 5 rows you select\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d71045",
   "metadata": {},
   "source": [
    "### 1.1.3 Use kafka brokers and topics to send your data event by event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### persist Data locally to source the stream\n",
    "data.to_csv(\"./chicagodata/to_be_sent_into_kafka.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483b67d-7ec7-4335-a354-735166cb4d65",
   "metadata": {},
   "source": [
    "## Producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fb5b1-958b-4b5c-814e-6b0433d37fc6",
   "metadata": {},
   "source": [
    "#### Configure a producer that will send events to kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06ae13-6268-4faa-b481-1ab47c29bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicName = 'aiengineer.tp.1' # this is the topic where we will produce events\n",
    "kafkabrokers=\"https://streaming-bridge.course.aiengineer.codex-platform.com\" #the link to the messaging service\n",
    "headers={'content-type': 'application/vnd.kafka.binary.v2+json'} #metadata to define the message format/encoding\n",
    "keyName=''#name-surname   #the key you will use to get the data when consuming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb5d90-2405-416a-abf0-5c587bcada86",
   "metadata": {},
   "source": [
    "#### Send each line from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6946a0a",
   "metadata": {},
   "source": [
    "### Before executing the next cells, open and execute the last notebook : [2_receive_stream_data.ipynb](./2_receive_stream_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependancies : a python client that allow writing events to our kafka bridge\n",
    "%pip install kafka_bridge_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0733310-6b88-47a0-8087-3e03eac5ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependancies\n",
    "from kafka_bridge_client import KafkaBridgeProducer,Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307052b4-74db-4914-a302-24b9e3f8c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the producer, that will connect and write to the messaging system\n",
    "producer = KafkaBridgeProducer(kafkabrokers,timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d446d3-d98d-4584-b2e3-5ce479c61c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stram our chicago dataset line per line in bytes format to the messaging system\n",
    "with open(\"./chicagodata/to_be_sent_into_kafka.csv\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # only send the 10 first lines, exept the header in position 0\n",
    "        if i > 0 and i < 10:\n",
    "            producer.send(\n",
    "                topic=topicName,\n",
    "                # Create a Message object containing our key and our line byte encoded (src encoding is 'utf-8')\n",
    "                record = Message(key=keyName,value=bytes(line,'utf-8')),\n",
    "                binary=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41509f2d-1933-4224-b238-6d9ce1e6399d",
   "metadata": {},
   "source": [
    "### 1.1.4 Visualize on superset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96cf398-9ef3-4c54-a5fd-7c85936da60d",
   "metadata": {},
   "source": [
    "Go to [https://dataviz.course.aiengineer.codex-platform.com/](https://dataviz.course.aiengineer.codex-platform.com/) (or look for superset in product portal) and log with your account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff58f48-59e1-4f6f-a37d-a8ebeb25457b",
   "metadata": {},
   "source": [
    "on Data > Databases you should see a database named `clickhouse`. This will be our source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e61b74-76e0-488d-9f3d-7e0b46ffa2dc",
   "metadata": {},
   "source": [
    "![source](./images/source.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b8105f-e5cc-4626-a305-9e6008685a42",
   "metadata": {},
   "source": [
    "With this source we will create a superset dataset. It maps a table and allow exploration/ chart creation using it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131da8d-9301-4445-9dde-21506b670752",
   "metadata": {},
   "source": [
    "![dataset](./images/dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e2f0c-0d1e-419e-aec3-f965eeef5d3f",
   "metadata": {},
   "source": [
    "![table](./images/table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ce56f-546d-4d52-b595-de4869352a35",
   "metadata": {},
   "source": [
    "One you choose the dataset, click on it and start create some charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2c2d1-bc83-4fce-bfe3-7dd1f1c2b0b1",
   "metadata": {},
   "source": [
    "![tips](./images/tips.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a058d-abeb-444e-a539-f9bd28223c16",
   "metadata": {},
   "source": [
    "**In this example**\n",
    "\n",
    "- Chart type is bar chart\n",
    "- No time range because dataset has old dates values\n",
    "- metric is average tips (y)\n",
    "- serie is pickup location (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b37c06-a0a0-42b9-a2c2-c4602ad2d36e",
   "metadata": {},
   "source": [
    "You can name, save and assign chart to a dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb54d62-024c-41ce-967f-85aba9f4c39e",
   "metadata": {},
   "source": [
    "**Go further : Create a dashboard with multiple vizualisation answering to feature analysis, try to represent the dataset on a map**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1db6d0c0fb62fcd92812f526c45c77dc568410c92bb0ad7cc615a53ad33175c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
